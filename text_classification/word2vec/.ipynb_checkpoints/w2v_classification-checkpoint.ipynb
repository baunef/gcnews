{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c86b261",
   "metadata": {},
   "source": [
    "# Word2Vec Training + Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "439c7a8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV, RidgeClassifierCV, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve, RocCurveDisplay\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb153d4d",
   "metadata": {},
   "source": [
    "Load German Word2Vec model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab637983",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('german'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([word for word in text if word not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fcc2cb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9edc7531",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gc_news = pd.read_csv(\"../../data/gcnews/gc_news_unlabeled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1feb64a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       text\n",
      "label      \n",
      "0       199\n",
      "1       199\n"
     ]
    }
   ],
   "source": [
    "labeled_data = pd.read_csv('../../data/ground_truth/labeled_data.csv', header=None, names=[\"text\", \"label\"])\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], train_size=100, random_state=24)\n",
    "\n",
    "print(labeled_data.groupby(\"label\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1e1f9cc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = labeled_data['text'].apply(preprocess)\n",
    "gc_news_text = gc_news.Content.apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f833d0",
   "metadata": {},
   "source": [
    "# Train Word2Vec\n",
    "\n",
    "The Word2Vec model is trained with the entire unlabeled `gc_news` text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40c52fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sentence.split() for sentence in gc_news_text]\n",
    "w2v_model = Word2Vec(sentences, vector_size=300, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d93bcb2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f684216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sentence):\n",
    "    words = sentence.split()\n",
    "    words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
    "    if len(words_vecs) == 0:\n",
    "        return np.zeros(300)\n",
    "    words_vecs = np.array(words_vecs)\n",
    "    return words_vecs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd886aee",
   "metadata": {},
   "source": [
    "# Validation\n",
    "\n",
    "A Logistic Regression is fitted to 100 training observations and tested against the remaining labeled data. This process is repeated with five different random states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b91bc9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random state 100: Achieved f1 = 0.76 w/ LogReg in training.\n",
      "PR-AUC Score: 0.6066236040969879\n",
      "Random state 200: Achieved f1 = 0.65 w/ LogReg in training.\n",
      "PR-AUC Score: 0.5792685108354013\n",
      "Random state 300: Achieved f1 = 0.80 w/ LogReg in training.\n",
      "PR-AUC Score: 0.6228374216330359\n",
      "Random state 400: Achieved f1 = 0.99 w/ LogReg in training.\n",
      "PR-AUC Score: 0.5183072412417644\n",
      "Random state 500: Achieved f1 = 0.92 w/ LogReg in training.\n",
      "PR-AUC Score: 0.5723897922228874\n",
      "accuracy: \t 0.5477 +- 0.0287 \n",
      "precision: \t 0.5501 +- 0.0305 \n",
      "recall: \t 0.5477 +- 0.0287 \n",
      "f1-score: \t 0.5431 +- 0.0275 \n",
      "PR-AUC: \t 0.5799 +- 0.0358 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_states = [100,200,300,400,500]\n",
    "output = []\n",
    "pr_auc_scores = []\n",
    "\n",
    "X = np.array([vectorize(sentence) for sentence in labeled_data['text']])\n",
    "y = labeled_data['label']\n",
    "\n",
    "for rs in random_states:\n",
    "    train_stats, test_stats, train_labels, test_labels = train_test_split(X, y, train_size=100, stratify=y, random_state=rs)\n",
    "    log = LogisticRegressionCV(cv=5, max_iter=500, random_state=42)\n",
    "    log.fit(train_stats, train_labels)\n",
    "    output.append(classification_report(test_labels, log.predict(test_stats), output_dict=True))\n",
    "    print(\"Random state %d: Achieved f1 = %.2f w/ LogReg in training.\" % (\n",
    "        rs, \n",
    "        classification_report(\n",
    "            train_labels, \n",
    "            log.predict(train_stats), \n",
    "            output_dict=True\n",
    "        )['weighted avg']['f1-score']\n",
    "    ))\n",
    "    precision, recall,_= precision_recall_curve(test_labels, log.predict_proba(test_stats)[:,1]) \n",
    "    pr_auc = auc(recall, precision)\n",
    "    # Print the PR-AUC Score \n",
    "    print(\"PR-AUC Score:\", pr_auc)\n",
    "    pr_auc_scores.append(pr_auc)\n",
    "\n",
    "    \n",
    "scores = pd.json_normalize(output)\n",
    "\n",
    "accuracy = (np.mean(scores.accuracy), np.std(scores.accuracy))\n",
    "precision = np.mean(scores['weighted avg.precision']), np.std(scores['weighted avg.precision'])\n",
    "recall = np.mean(scores['weighted avg.recall']), np.std(scores['weighted avg.recall'])\n",
    "f1 = np.mean(scores['weighted avg.f1-score']), np.std(scores['weighted avg.f1-score'])\n",
    "pr_auc = np.mean(pr_auc_scores), np.std(pr_auc_scores)\n",
    "\n",
    "print(\n",
    "\"accuracy: \\t %.4f +- %.4f \\n\"\n",
    "\"precision: \\t %.4f +- %.4f \\n\"\n",
    "\"recall: \\t %.4f +- %.4f \\n\"\n",
    "\"f1-score: \\t %.4f +- %.4f \\n\"\n",
    "\"PR-AUC: \\t %.4f +- %.4f \\n\" % (accuracy[0], accuracy[1], \n",
    "                                precision[0], precision[1],\n",
    "                                recall[0], recall[1],\n",
    "                                f1[0], f1[1],\n",
    "                                pr_auc[0], pr_auc[1],\n",
    "                                  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d0d818",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "A Logistic Regression is fitted to the entire labeled data. The fitted Regression is used to predict labels for the `gc_news` data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48a4eef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81       199\n",
      "           1       0.82      0.78      0.80       199\n",
      "\n",
      "    accuracy                           0.80       398\n",
      "   macro avg       0.80      0.80      0.80       398\n",
      "weighted avg       0.80      0.80      0.80       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.array([vectorize(sentence) for sentence in labeled_data['text']])\n",
    "y = labeled_data['label']\n",
    "\n",
    "log = LogisticRegressionCV(cv=5, max_iter=10000, random_state=42)\n",
    "log.fit(X, y)\n",
    "\n",
    "print(classification_report(y, log.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "746b2f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_infer = np.array([vectorize(sentence) for sentence in gc_news_text])\n",
    "y_infer = log.predict(X_infer)\n",
    "y_proba = log.predict_proba(X_infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b6b0f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_news[\"label\"] = y_infer\n",
    "gc_news[\"proba\"] = y_proba[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781388c6",
   "metadata": {},
   "source": [
    "Uncomment to export labeled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7265247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gc_news.to_csv(\"gc_news_w2v_labels.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
